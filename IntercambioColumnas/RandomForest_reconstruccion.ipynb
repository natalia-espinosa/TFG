{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d2eec1-f58d-4390-ae69-2ce6600d3ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicción de precios de casas sin ruido:\n",
      "MSE: 0.2026487761161288\n",
      "MAE: 0.3014288578444504\n",
      "RMSE: 0.45016527644425086\n",
      "R2: 0.7867565451436587\n",
      "\n",
      "Reconstrucción de ingresos (sin ruido):\n",
      "MSE: 0.2636084318173617\n",
      "MAE: 0.3813467770336636\n",
      "RMSE: 0.5134281174783494\n",
      "R2: 0.8879443993029321\n",
      "\n",
      "Predicción de precios con ruido:\n",
      "MSE: 0.2058643390454658\n",
      "MAE: 0.30721661836771136\n",
      "RMSE: 0.4537227557060212\n",
      "R2: 0.783372869399341\n",
      "\n",
      "Reconstrucción de ingresos (con ruido):\n",
      "MSE: 7.664614201309953\n",
      "MAE: 2.1114984993218004\n",
      "RMSE: 2.7685039644743066\n",
      "R2: -2.2581012015356077\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score as r2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import model\n",
    "from model import read_data_model, add_laplace_noise\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Cargar los datos\n",
    "all_data = fetch_california_housing()\n",
    "X_train_val, X_val, X_test, Y_train_val, Y_val, Y_test = read_data_model(all_data, 'MedInc')\n",
    "\n",
    "# Escalado de los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_val_scaled = scaler.fit_transform(X_train_val)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Parámetros especificados para RandomForestRegressor\n",
    "best_params = {\n",
    "    'n_estimators': 300,\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'log2'\n",
    "}\n",
    "\n",
    "# Crear y entrenar el modelo con los parámetros especificados\n",
    "model_original = RandomForestRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    max_features=best_params['max_features'],\n",
    "    random_state=42\n",
    ")\n",
    "model_original.fit(X_train_val_scaled, Y_train_val)\n",
    "Y_predict = model_original.predict(X_test_scaled)\n",
    "\n",
    "# Evaluar el modelo original (sin ruido)\n",
    "MSE_original = mse(Y_test, Y_predict)\n",
    "MAE_original = mae(Y_test, Y_predict)\n",
    "RMSE_original = np.sqrt(MSE_original)\n",
    "R2_original = r2(Y_test, Y_predict)\n",
    "\n",
    "print(\"\\nPredicción de precios de casas sin ruido:\")\n",
    "print(f\"MSE: {MSE_original}\")\n",
    "print(f\"MAE: {MAE_original}\")\n",
    "print(f\"RMSE: {RMSE_original}\")\n",
    "print(f\"R2: {R2_original}\")\n",
    "\n",
    "# Paso 2: Crear nuevos datos de entrada reemplazando solo la columna de ingreso con las predicciones\n",
    "column_index = list(all_data.feature_names).index('MedInc')  # Índice de la columna de ingreso\n",
    "X_train_val_new = np.copy(X_train_val)\n",
    "X_test_new = np.copy(X_test)\n",
    "\n",
    "# Realiza la predicción en el conjunto de entrenamiento para el modelo original\n",
    "Y_predict_train = model_original.predict(X_train_val_scaled)\n",
    "\n",
    "# Reemplazar solo la columna de ingreso\n",
    "Y_train_val_new = X_train_val_new[:, column_index].copy()\n",
    "Y_test_new = X_test_new[:, column_index].copy()\n",
    "X_train_val_new[:, column_index] = Y_predict_train  \n",
    "X_test_new[:, column_index] = Y_predict \n",
    "\n",
    "scaler_reconstruct = StandardScaler()\n",
    "X_train_val_new_scaled = scaler_reconstruct.fit_transform(X_train_val_new)\n",
    "X_test_new_scaled = scaler_reconstruct.transform(X_test_new)\n",
    "\n",
    "# Reconstrucción de la columna de ingreso usando los datos sin ruido\n",
    "model_reconstruct = RandomForestRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    max_features=best_params['max_features'],\n",
    "    random_state=42\n",
    ")\n",
    "model_reconstruct.fit(X_train_val_new_scaled, Y_train_val_new)\n",
    "income_predict = model_reconstruct.predict(X_test_new_scaled)\n",
    "\n",
    "# Evaluar la reconstrucción de ingresos (sin ruido)\n",
    "MSE_income_reconstruct = mse(X_test[:, column_index], income_predict)\n",
    "MAE_income_reconstruct = mae(X_test[:, column_index], income_predict)\n",
    "RMSE_income_reconstruct = np.sqrt(MSE_income_reconstruct)\n",
    "R2_income_reconstruct = r2(X_test[:, column_index], income_predict)\n",
    "\n",
    "print(\"\\nReconstrucción de ingresos (sin ruido):\")\n",
    "print(f\"MSE: {MSE_income_reconstruct}\")\n",
    "print(f\"MAE: {MAE_income_reconstruct}\")\n",
    "print(f\"RMSE: {RMSE_income_reconstruct}\")\n",
    "print(f\"R2: {R2_income_reconstruct}\")\n",
    "\n",
    "# Paso 4: Añadir ruido Laplaciano a la columna de ingreso y repetir el procedimiento\n",
    "epsilon = 1  # Usamos el epsilon ya seleccionado\n",
    "X_train_val_noisy = add_laplace_noise(X_train_val, epsilon)\n",
    "scalerRuido = StandardScaler()\n",
    "X_train_val_noisy_scaled = scalerRuido.fit_transform(X_train_val_noisy)\n",
    "X_test_scaled = scalerRuido.transform(X_test)\n",
    "\n",
    "# Entrenar el modelo con datos ruidosos\n",
    "model_noisy = RandomForestRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    max_features=best_params['max_features'],\n",
    "    random_state=42\n",
    ")\n",
    "model_noisy.fit(X_train_val_noisy_scaled, Y_train_val)\n",
    "Y_predict_noisy = model_noisy.predict(X_test_scaled)\n",
    "\n",
    "# Evaluar el modelo con datos ruidosos\n",
    "MSE_noisy = mse(Y_test, Y_predict_noisy)\n",
    "MAE_noisy = mae(Y_test, Y_predict_noisy)\n",
    "RMSE_noisy = np.sqrt(MSE_noisy)\n",
    "R2_noisy = r2(Y_test, Y_predict_noisy)\n",
    "\n",
    "print(\"\\nPredicción de precios con ruido:\")\n",
    "print(f\"MSE: {MSE_noisy}\")\n",
    "print(f\"MAE: {MAE_noisy}\")\n",
    "print(f\"RMSE: {RMSE_noisy}\")\n",
    "print(f\"R2: {R2_noisy}\")\n",
    "\n",
    "# Paso 5: Crear nuevos datos de entrada reemplazando la columna de ingreso con las predicciones ruidosas\n",
    "X_train_val_new_noisy = np.copy(X_train_val_noisy)\n",
    "X_test_new = np.copy(X_test)\n",
    "\n",
    "# Realiza la predicción en el conjunto de entrenamiento con el modelo ruidoso\n",
    "Y_predict_train_noisy = model_noisy.predict(X_train_val_noisy_scaled)\n",
    "\n",
    "# Reemplazar solo la columna de ingreso con las predicciones ruidosas\n",
    "Y_train_val_new = X_train_val_new_noisy[:, column_index].copy()\n",
    "Y_test_new = X_test_new[:, column_index].copy()\n",
    "X_train_val_new_noisy[:, column_index] = Y_predict_train_noisy  \n",
    "X_test_new[:, column_index] = Y_predict\n",
    "\n",
    "scaler_reconstruct = StandardScaler()\n",
    "X_train_val_new_scaled_noisy = scaler_reconstruct.fit_transform(X_train_val_new_noisy)\n",
    "X_test_new_scaled = scaler_reconstruct.transform(X_test_new)\n",
    "\n",
    "# Reconstrucción de la columna de ingreso con datos ruidosos\n",
    "model_reconstruct_noisy = RandomForestRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    max_features=best_params['max_features'],\n",
    "    random_state=42\n",
    ")\n",
    "model_reconstruct_noisy.fit(X_train_val_new_scaled_noisy, Y_train_val_new)\n",
    "income_predict_noisy = model_reconstruct_noisy.predict(X_test_new_scaled)\n",
    "\n",
    "# Evaluar la reconstrucción de ingresos (con ruido)\n",
    "MSE_income_reconstruct_noisy = mse(X_test[:, column_index], income_predict_noisy)\n",
    "MAE_income_reconstruct_noisy = mae(X_test[:, column_index], income_predict_noisy)\n",
    "RMSE_income_reconstruct_noisy = np.sqrt(MSE_income_reconstruct_noisy)\n",
    "R2_income_reconstruct_noisy = r2(X_test[:, column_index], income_predict_noisy)\n",
    "\n",
    "print(\"\\nReconstrucción de ingresos (con ruido):\")\n",
    "print(f\"MSE: {MSE_income_reconstruct_noisy}\")\n",
    "print(f\"MAE: {MAE_income_reconstruct_noisy}\")\n",
    "print(f\"RMSE: {RMSE_income_reconstruct_noisy}\")\n",
    "print(f\"R2: {R2_income_reconstruct_noisy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
